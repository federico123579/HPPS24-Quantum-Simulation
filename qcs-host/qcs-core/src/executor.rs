//! This module collects executors, which are responsible for executing the instructions
//! generated by the scheduler.
//!
//! As for now there is only one executor, the `CpuExecutor`, which is responsible for
//! executing the instructions on the CPU.

use std::{fmt::Debug, sync::Arc, thread::JoinHandle};

use crossbeam::channel::unbounded;
use dashmap::{DashMap, DashSet};

use crate::{model::blocks::BlockLike, scheduler::ExecutionOperand};

pub trait InstructionLike: Computation + Debug {
    fn id(&self) -> usize;
}

pub trait ExecutorPlan {
    type Instruction: InstructionLike;

    fn get_ready(&self) -> Vec<usize>;
    fn set_done(&mut self, ids: impl IntoIterator<Item = usize>);
    fn fetch_ready(&mut self) -> Vec<Self::Instruction>;
    fn is_empty(&self) -> bool;
}

pub trait BlockStore<B: BlockLike> {
    fn load_block(&self, operand: ExecutionOperand<B>) -> B;
    fn save_block(&self, id: usize, block: B);
    // fn prepare_computation(&self, instruction: ContractionInstruction) -> Computation;
}

impl<B: BlockLike> BlockStore<B> for DashMap<usize, B> {
    /// Loads a block from memory or from the instruction.
    #[inline]
    fn load_block(&self, instruction: ExecutionOperand<B>) -> B {
        match instruction {
            ExecutionOperand::Block(block) => block,
            ExecutionOperand::Address(id) => self.remove(&id).unwrap().1,
        }
    }

    /// Saves a block in memory.
    #[inline]
    fn save_block(&self, id: usize, block: B) {
        self.insert(id, block);
    }
}

pub trait Computation {
    type BlockKind: BlockLike;

    fn compute(self, block_map: &impl BlockStore<Self::BlockKind>) -> usize;
}

/// The `CpuExecutor` is responsible for executing the instructions on the CPU.
#[derive(Debug, Default)]
pub struct CpuExecutor<B: BlockLike> {
    /// The memory of the executor, which is a map from the id of the block to the block itself.
    memory: Arc<DashMap<usize, B>>,
    threads: Vec<JoinHandle<()>>,
}

impl<B> CpuExecutor<B>
where
    B: BlockLike + Send + Sync + 'static,
{
    /// Creates a new `CpuExecutor`.
    pub fn new() -> Self {
        Self {
            memory: Arc::new(DashMap::new()),
            threads: Vec::new(),
        }
    }

    /// Spawns a new thread and keeps track of it.
    pub fn spawn<F>(&mut self, f: F)
    where
        F: FnOnce() + Send + 'static,
    {
        self.threads.push(std::thread::spawn(f))
    }

    /// Wait for all thread completion.
    pub fn join_all(&mut self) {
        for thread in self.threads.drain(..) {
            let _ = thread.join();
        }
    }

    /// Execute a contraction plan, in parallel.
    pub fn execute<E, I>(mut self, mut plan: E) -> Vec<B>
    where
        I: Computation<BlockKind = B> + InstructionLike + Send + 'static,
        E: ExecutorPlan<Instruction = I> + Send + 'static,
    {
        // create a channel to communicate the need of more instructions
        let (wtx, wrx) = unbounded();
        let (itx, irx) = unbounded();
        // create a set of usize to keep track of current execution
        let executing = Arc::new(DashSet::new());

        // spawn a thread that fills the queue with the ready instructions
        self.spawn(move || {
            for instruction in plan.fetch_ready() {
                executing.insert(instruction.id());
                itx.send(instruction).unwrap();
            }
            while let Ok(id) = wrx.recv() {
                plan.set_done(std::iter::once(id));
                for instruction in plan
                    .fetch_ready()
                    .into_iter()
                    .filter(|i| executing.insert(i.id()))
                {
                    itx.send(instruction).unwrap();
                }
                if plan.is_empty() {
                    break;
                }
            }
        });

        // spawn many thread as cpu cores to execute the instructions
        for _ in 0..num_cpus::get() {
            let wtx_clone = wtx.clone();
            let irx_clone = irx.clone();
            let block_map = Arc::clone(&self.memory);
            self.spawn(move || {
                while let Ok(instruction) = irx_clone.recv() {
                    let id = instruction.compute(&*block_map);
                    if wtx_clone.send(id).is_err() {
                        break;
                    }
                }
            });
        }

        // wait for all threads to finish
        self.join_all();

        Arc::try_unwrap(self.memory)
            .unwrap()
            .into_iter()
            .map(|(_, block)| block)
            .collect()
    }
}
